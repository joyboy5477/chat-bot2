{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "                         /Users/joyboyav/Desktop/Mlops/Foundations/Mlops/End2End/env\n",
      "base                     /Users/joyboyav/anaconda3\n",
      "c2                    *  /Users/joyboyav/anaconda3/envs/c2\n",
      "chat                     /Users/joyboyav/anaconda3/envs/chat\n",
      "demo                     /Users/joyboyav/anaconda3/envs/demo\n",
      "mlr                      /Users/joyboyav/anaconda3/envs/mlr\n",
      "nlp                      /Users/joyboyav/anaconda3/envs/nlp\n",
      "tweet                    /Users/joyboyav/anaconda3/envs/tweet\n",
      "youtube                  /Users/joyboyav/anaconda3/envs/youtube\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyboyav/anaconda3/envs/c2/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"6ca76a00-c508-411b-86d0-ce44394b5521\" #this is from API key\n",
    "PINECONE_API_ENV = \"gcp-starter\" #this is index key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"data/G.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/G.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4133"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download embedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "# LEts test it\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# PINECONE_API_KEY = \"6ca76a00-c508-411b-86d0-ce44394b5521\" #this is from API key\n",
    "# PINECONE_API_ENV = \"gcp-starter\" #this is index key\n",
    "# export PINECONE_API_KEY=\"6ca76a00-c508-411b-86d0-ce44394b5521\" # on terminal\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '6ca76a00-c508-411b-86d0-ce44394b5521')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have an index, you can load it like this\n",
    "index_name = \"chat-bot\"\n",
    "index = pc.Index(host='https://chat-bot-gdxe800.svc.gcp-starter.pinecone.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Assuming embeddings_model is your loaded model for generating embeddings\n",
    "embeddingslist = []\n",
    "for doc in text_chunks:\n",
    "    page_content = doc.page_content\n",
    "    # Generate an embedding for the page_content\n",
    "    embed = model.encode([page_content])  # Adjust based on your model's API\n",
    "    embeddingslist.append(embed)\n",
    "\n",
    "# Now, embeddings is a list of embeddings corresponding to your Document objects\n",
    "\n",
    "# Assuming embeddings are a list of lists (nested), where each inner list should be concatenated\n",
    "corrected_data_to_upload = []\n",
    "for i, (text, embedding) in enumerate(zip(text_chunks, embeddingslist)):\n",
    "    # Flatten the nested list structure of each embedding into a flat list\n",
    "    flat_vector = [item for sublist in embedding for item in sublist] if isinstance(embedding[0], list) else embedding\n",
    "    corrected_data_to_upload.append((str(i), flat_vector, {\"text\": text}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PINECONE_API_KEY='your_pinecone_api_key_here'\n",
    "# export PINECONE_INDEX_NAME='your_index_name_here'\n",
    "\n",
    "# os.environ.get('PINECONE_API_KEY', '6ca76a00-c508-411b-86d0-ce44394b5521')\n",
    "# os.environ.get('PINECONE_API_ENV', 'gcp-starter')\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['PINECONE_API_KEY'] = '6ca76a00-c508-411b-86d0-ce44394b5521'\n",
    "os.environ['PINECONE_INDEX_NAME'] = \"chat-bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(text_chunks, embeddings, index_name=\"chat-bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Bhagavad-Gita As It Is\" by  A.C. Bhaktivedanta Swami \n",
      "Prabhupada, courtesy of th e Bhaktivedanta Book Trust \n",
      "International, www.Krishna.com .\" \n",
      " \n",
      "This book and electronic file is Copyright 1972-2004 \n",
      "Bhaktivedanta Book Tr ust International, 3764 Watseka Avenue, \n",
      "Los Angeles, California 90034, USA. All rights reserved. For any \n",
      "questions, comments, corresponde nce, or to evaluate dozens of \n",
      "other books in this collection, vi sit the website of the publishers, \n",
      "www.Krishna.com .\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is krishna?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
